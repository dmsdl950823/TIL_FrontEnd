- [Shaders](#shaders)
- [Shader 란?](#shader-란)
  - [Vertex shader](#vertex-shader)
  - [Fragment shader](#fragment-shader)
  - [결론](#결론)
  - [shader 를 직접 작성해서 사용해야 하는 이유](#shader-를-직접-작성해서-사용해야-하는-이유)
- [RawShaderMaterial 을 이용한 shader 생성하기](#rawshadermaterial-을-이용한-shader-생성하기)
  - [Shader 를 각자 다른파일에 위치시키기](#shader-를-각자-다른파일에-위치시키기)
  - [Shader files](#shader-files)
- [Import](#import)
  - [Properties](#properties)
- [GLSL](#glsl)
- [vertex shader 이해하기](#vertex-shader-이해하기)
  - [gl_Position](#gl_position)
  - [Position 속성](#position-속성)
  - [Matrices uniforms](#matrices-uniforms)
- [Fragment Shader 이해하기](#fragment-shader-이해하기)

# Shaders

Shader 는 Three.js 내장 API를 사용하여 생성할때, 해당 API 들은 shader 로 작성되어있는 방식들입니다. WebGL 렌더에서 보여지는 모든것들은 shader 덕분에 가능한 것이지만, 직접 만들어야할 때가 많습니다.

이제부터 언제, 무슨 shader 를 사용해야하는지부터 배울 것 입니다. 그리고는 shader 문법을 배워 간단한 shader 들을 만들것입니다. 


# Shader 란?

shader 는, 사실 WebGL 의 주요 컴포넌트중 하나입니다. 만약 WebGL 을 Three.js 없이 사용하게 된다면, 제일 먼저 배워야 하는게 shader 입니다. 그러나 이 개념은 매우 어렵죠.

shader 는 GLSL 로 작성됩니다. GLSL 은 GPU 로 보내지며, 각 geometry 의 꼭지점의 위치가 사용되고, 그 geomtry 의 보이는 pixel 색상을 보여줍니다. 여기서 "pixel" 은 정확하지 않습니다 - 왜냐하면 렌더링의 각 포인트는 필수적으로 스크린의 각 pixel 에 일치하는 것은 아니기 때문입니다. 그리고 이것이 왜 우리가 "**fragment** (파편)" 라는 용어를 선호하는지 에 대한 이유입니다. 

아무튼, 그 후, 우리는 많은 데이터를 shader 에게 보냅니다. 예를들어 꼭짓점 위치, mesh transformation, camera 정보, 우리가 보는 view, 생상, 질감, 조명, 안개 등등의 parameter 등을 말이죠. 그러면 GPU 는 이 모든 데이터를 shader 의 가이드에 따라 처리하며, 우리의 geometry 는 렌더되어 화면에 표시됩니다.

두 가지 타입의 shader 가 있으며, 둘 다 필요합니다.

## Vertex shader

*vertex shader* 의 목적은 geometry 의 꼭짓점 위치(position)를 나타내기 위함입니다. 해당 개념은 꼭지점 위치(position), mesh 의 변형 (position, rotation, scale 등), 카메라 정보 (position, rotation, field of view 등) 을 전송합니다. 그리고 GPU 는 vertex shader 안에 있는 정보를 따라 프로젝트를 2D 공간에 렌더링 하기위해서 - canvas에 모든 정보를 처리합니다.

vertex shader 를 사용할 때, 이 코드는 모든 geometry 의 꼭지점에 적용될 것입니다. 
* 몇몇 데이터 (꼭지점 position 등 과 같이..)는 각 꼭지점을 변경시킬것 입니다. 꼭지점 사이를 변경하는 이러한 데이터는, `attribute` 라고 부릅니다.
* 그러나 몇몇 데이터는 각 꼭짓점 위치 사이를 변경할 필요는 없습니다. 꼭지점 사이를 변경하지 않는, 이러한 데이터는 `uniform` 이라고 부릅니다.

이 두 데이터 타입은 뒤에서 배울 것 입니다.

vertex shader 는 제일먼저 발생합니다. 일단 꼭짓점이 생성되어 위치되면, GPU 는 geometry 의 어떠한 픽셀들이 보이게 되며, 그 후 fragment shader 로 전달됩니다.

## Fragment shader

*fragment shader* 의 목적은 geometry 에 보이는 각 파편(fragment) 들 에게 색상을 입히는 것 입니다.

같은 fragment shader 는 모든 geometry 의 보이는 모든 파편에 사용됩니다. 우리는 데이터를 fragment shader 에 전달하여, `uniforms` 를 사용하여 컬러를 설정할 수 있습니다. vetex shader 와 같이, 또는 vertex shader 에서 전달받은 데이터(이러한 타입의 데이터를 `varying` 이라고 부릅니다. 이 데이터는 후에 확인할 것 입니다)를 활용할 수 있습니다.

fragment shader 에서 가장 직접적인 정보는 모든 파편들에게 모두 같은 color 를 입히도록 하는 것 입니다. 색상 특성만 잘 설정했다면 [MeshBasicMaterial](https://threejs.org/docs/index.html#api/en/materials/MeshBasicMaterial)과 같은 결과를 얻을 수 있습니다.

또는 데이터를 shader 에게 전달해 줄 수도 있습니다.(ex. light 위치) 그리고 얼마나 많은 물체들/표면들이 해당 light 자원을 받고있는지에 따라서 해당 파편에 색상을 입힐 수 있습니다. 이 결과는 한 개의 light 를 scene 에 가지고 있다면, [MeshPhongMaterial](https://threejs.org/docs/index.html#api/en/materials/MeshPhongMaterial) 와 같은 결과를 얻을 수 있습니다.


## 결론

**vertex shader** 는 꼭지점의 position 을 렌더링한다.

**fragment shader** 는 geometry 의 보여지는 각 파편/표면(fragment) 의 색상을 표현한다.

**fragment shader** 는 **vertex shader** 다음에 실행된다.

(position 등과 같이) 각 꼭지점의 변화는 `attribute` 라고 불리며, **vertex shader** 에서만 사용된다.

(position 이나 color 등과 같이) 각 꼭지점이 변하지 않는 데이터는 `uniform` 이라고 불리며, **vertex shader** 와 **fragment shader** 둘다 사용 가능하다.

`varying` 을 통해 **vertext shader** 에서 **fragment shader** 로 데이터를 내보낼 수 있다.


## shader 를 직접 작성해서 사용해야 하는 이유

Three.js material 은 많은 상황들을 처리할수 있도록 설계되었지만, 한계가 있습니다. 이 한계를 넘어서기 위해선 직접 작성한 shader 를 사용해야합니다.

또, 퍼포먼스 문제가 있을 수 있습니다. [MeshStandardMaterial](https://threejs.org/docs/index.html#api/en/materials/MeshStandardMaterial) 같은 material 은 아주 정교하고 많은 코드라인과 계산들을 포함합니다. 만약 우리만의 shader 를 작성해야한다면, 계산 등을 최소화 해야합니다. 퍼포먼스를 더 잘 관리할 필요가 있습니다.

또한 shader 를 직접 작성하는것은 렌더링 할때 후가공(post-process) 하는 가장 최고의 방법입니다.

일단 shader 를 마스터 하고나면, 모든 프로젝트에서 필수품이 될 것 입니다.

--------
# RawShaderMaterial 을 이용한 shader 생성하기

shader 를 작성하기 위해서는, 특별한 material 를 만들필요가 있습니다. 이 material 은 [ShaderMaterial](https://threejs.org/docs/index.html#api/en/materials/ShaderMaterial) 이나 [RawShaderMaterial](https://threejs.org/docs/index.html#api/en/materials/RawShaderMaterial) 일 수 있습니다. 이 두 클래스의 차이는 ShaderMaterial 은 자동으로 shader 코드를 추가해주지만, RawShaderMaterial 은 이름처럼 아무것도 갖지않는 클래스입니다.

어떤일이 일어나는지 확인하기 위해 RawShaderMaterial 로 시작해볼 것입니다. 

``` js
  const material = new THREE.RawShaderMaterial()
```

이렇게 설정한 경우, 에러를 받게됩니다.

이전에 말했듯이, vertex shader 와 fragment shader 를 제공해야합니다. `vertexShader` 와 `fragmentShader` 프로퍼티를 제공합니다.

``` js
  const material = new THREE.RawShaderMaterial({
    vertexShader: `
      uniform mat4 projectionMatrix;
      uniform mat4 viewMatrix;
      uniform mat4 modelMatrix;

      attribute vec3 position;

      void main()
      {
          gl_Position = projectionMatrix * viewMatrix * modelMatrix * vec4(position, 1.0);
      }
    `,
    fragmentShader: `
      precision mediump float;

      void main()
      {
          gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0);
      }
    `
  })
```

<img src="https://threejs-journey.xyz/assets/lessons/24/step-01.png" width="500">

이렇게 하면 red plane 이 만들어집니다. 축하합니다~~ 어떤 내용이 적혀있는지는 현재로선 알 수 없지만, 시작이 좋습니다.

## Shader 를 각자 다른파일에 위치시키기

코드를 추가하기 전에, 문자열로 받는 shader 코드는 라인이 많으면 사용하기 불편합니다. 파일로 따로 빼는게 좋습니다.

## Shader files

vertex shader 코드와 fragment shader 코드를 따로따로  `/src/shaders/test/vertex.glsl` `/src/shaders/test/fragment` 에 생성합니다.

VS Code 를 사용하고있다면 플러그인을 사용해 glsl syntax coloration 과 Shader language 를 설치하여 가독성을 위해 코드 색상을 설정합니다.

linter 를 설치하여 코드를 검토하고, 작성중에 발생하는 잠재적인 에러들을 확인하세요. 테스트 결과가 브라우저에 표시되지 않기때문에 기본적인 실수들을 방지할 때 도움이 됩니다.

# Import

`script.js` 파일에 shader 파일을 import 시킵니다.

``` js
  import testVertexShader from './shaders/test/vertex.glsl'
  import testFragmentShader from './shaders/test/fragment.glsl'
```

import 시킬경우, webpack 에러가 발생합니다. Webpack 에게 어떻게 `.glsl` 파일을 읽어야하는지 알려주어야 합니다. `/bundler/webpack.common.js` 에 가서, `rules` 에 프로퍼티를 추가합니다.

``` js
  module.exports = {
    // ...

    module:
    {
      rules:
      [
        // ...

        // Shaders
        {
          test: /\.(glsl|vs|fs|vert|frag)$/,
          exclude: /node_modules/,
          use: [
            'raw-loader'
          ]
        }
      ]
    }
  }
```

해당 규칙은 Webpack 에게 .glsl, .vs, .fs, .vert, .frag 확장자 파일을 가질 수 있도록 알려주는 것 입니다. .glsl 만 사용하긴 하지만, 다른 파일 확장자를 설정해두면 편리합니다.

`npm run dev` 명령어로 서버를 다시 시작하면, Webpack 에러는 사라질 것 입니다.

`testVertextShader` 과 `testFragmentShader` 를 확인해보면, shader 코드가 이제 일반 string 으로 가져와지는 것을 확인할 수 있습니다. 이제 이 두개의 변수를 [RawShaderMaterial](https://threejs.org/docs/index.html#api/en/materials/RawShaderMaterial) 에서 사용할 수 있습니다.

``` js
  const material = new THREE.RawShaderMaterial({
    vertexShader: testVertexShader,
    fragmentShader: testFragmentShader
  })
```

## Properties

`wireframe`, `side`, `transparent`, `flatShading` 같이 일반적으로 materials 에서 사용하는 프로퍼티 대부분은 여전히 RawShaderMaterial

Most of the common properties we've covered with other materials such as wireframe, side, transparent or flatShading are still available for the [RawShaderMaterial](https://threejs.org/docs/index.html#api/en/materials/RawShaderMaterial) 에서 사용 가능합니다.


그러나 `map`, `alphaMap`, `opacity`, `color` 등은 shader 에서 직접 설정되기 때문에 더이상 동작하지않습니다.

``` js
  const material = new THREE.RawShaderMaterial({
    vertexShader: testVertexShader,
    fragmentShader: testFragmentShader,
    wireframe: true
  })
```

<img src="https://threejs-journey.xyz/assets/lessons/24/step-03.png" width="500"/>


# GLSL


GLSL 문법은 [여기](./210726_24%20Shaders%20-%20GLSL.md)를 참고하세요

# vertex shader 이해하기

위 포스팅을 확인했다면, shader 내부에 무엇이 있는지 이해할 필요가 있습니다.

vertex shader 의 목적은 2D 공간에 geometry 의 각 꼭지점의 위치를 변경하는데 있다는 것을 기억하세요. 다른말로, vertex shader 는 2D 캔버스 에 3D 꼭지점 객체를 옮기는 것 입니다.

## gl_Position

`gl_Position` 변수는 스크린의 꼭지점 위치를 포함하고있는 변수입니다. `main` function 에서 변수를 적절하게 설정할 수 있도록 설정합니다.

`vec4` 를 이용하여, `x`,`y`,`z`,`w` 프로퍼티를 직접적으로 `gl_Position` 변수에 입력할 수 있습니다.

``` c
  void main () {
    gl_Position = projectionMatrix * viewMatrix * modelMatrix * vec4(position, 1.0);
    gl_Position.x += 0.5;
    gl_Position.y += 0.5;
  }
```

plane geometry 는 오른쪽으로 이동하게됩니다. 그러나 실제로 3D 공간에서 움직인 것이 아니라, plane 을 2D 공간에 비춘것(projected) 뿐 입니다. Three.js의 `position` 처럼 실제로 움직인 것이 아닙니다.

종이에 그림을 그린다고 생각하면 됩니다. 그림에서, 원근법을 그리고, 그림을 그린 종이를 책상 옆으로 옮긴것 입니다. 그림 내부의 원근법은 변화가 없습니다.

`gl_Position`의 최종 목표가 2D 공간에 꼭짓점을 배치하는 것이라면 `gl_Position`에 4개의 값이 필요한 이유가 궁금할 것입니다. 사실 좌표 때문인지 정확히 2D 공간에 있지 않기 때문인지 4차원이 필요한 clip space 에 있습니다.

clip space 는 세 개의 방향(`x`, `y`, `z`)으로 가는 `-1` 부터 `1` 값을 가지는 공간입니다. 3D 박스에 무엇이든 위치시킬 수 있는 것 입니다. 이 범위의 모든것은 `clipped` 되어, 사라집니다. 4 번째 값인 `w` 는 원근을 책임집니다.

다행히도, 이 모든것은 자동이고, 우린 초보들이기 때문에 모든걸 마스터할 필요는 없습니다. 그냥 알아두기만 하면 됩니다.

근데 정확히 `gl_Position` 에게 무슨 정보를 전달해주고 있는걸까요?

## Position 속성

먼저, 아래 코드로 꼭지점 ``position`` 을 받습니다.

``` c
  attribute vec3 position;
```

geometry 의 모든 꼭지점에 동일한 코드가 적용된다는것을 기억하세요. **Attribute** 는 꼭지점을 변화시키는 하나의 변수입니다. 같은 vertex shader 는 모든 꼭지점에 적용되고, `position` attribute 는 `x`, `y`, `z` 위치에 모두 적용됩니다.

그리고 `vec3` 를 `vec4` 로 변경시킵니다.

``` c
  gl_Position = vec4(position, 1.0)
```

이것은 아래의 matrices 와 `gl_Position` 이 `vec4` 를 필요로 하기 때문입니다.

## Matrices uniforms

각 matrix 는 마지막 clip space 좌표를 가질 때 까지 `position` 을 변화시킵니다.

코드에 3 개의 matrics 가 있는데, geometry 의 모든 꼭지점을 위한 같은 값을 가집니다. 이 값들을 모두 **uniform** 을 사용하여 가져옵니다.

``` c
  uniform mat4 projectionMatrix;
  uniform mat4 viewMatrix;
  uniform mat4 modelMatrix;
```

각 matrix 는 변화를 만들어 냅니다.
* `modelMatrix` 는 [Mesh](https://threejs.org/docs/#api/en/objects/Mesh) 에 관련된 모든 것을 변화시킵니다. scale, rotate, Mesh 의 이동 등은 `modelMatrix` 에 포함되고, `position` 에 적용됩니다.
* `viewMatrix` 는 카메라에 관련된 변화를 적용합니다. camera 를 왼쪽으로 회전시키면, 꼭지점은 오른쪽에 있게 됩니다. ...
* `projectionMatrix` 는 좌표를 clip space 의 좌표로 바꿀 것 입니다.

이 matrices 에 대한 정보를 확인하고싶은경우, [여기](https://learnopengl.com/Getting-started/Coordinate-Systems) 를 참고하세요.

matrix 를 적용하기 위해서는, 곱해야합니다. 이 변수는 `vec4` 가 필요합니다. 다른 matrices 를 곱하여 만들 수 있습니다.

``` c
  gl_Position = projectionMatrix * viewMatrix * modelMatrix * vec4(position, 1.0)
```

`vieMatrix` 와 `modelMatrix` 를 `modelViewMatrix` 에 포함시킨 더 짧은 버전도 있습니다. 

``` c
  uniform mat4 projectionMatrix;
  uniform mat4 modelViewMatrix;

  attribute vec3 position;

  void main()
  {
    gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
  }
```

더 짧은 코드지만, 다루기는 조금더 쉬울것 입니다. 우리 코드를 이해하기 쉽도록, 조금더 풀어 써보겠습니다.

``` c
  uniform mat4 projectionMatrix;
  uniform mat4 viewMatrix;
  uniform mat4 modelMatrix;

  attribute vec3 position;

  void main()
  {
    vec4 modelPosition = modelMatrix * vec4(position, 1.0);
    vec4 viewPosition = viewMatrix * modelPosition;
    vec4 projectedPosition = projectionMatrix * viewPosition;

    gl_Position = projectedPosition;
  }
```

이러한 변화는 정확하게 같은 결과를 보여주지만, `modelPosition` 의 값을 변경시킴으로써 전체 모델을 움직일 수 있습니다.

``` c
  void main()
  {
    vec4 modelPosition = modelMatrix * vec4(position, 1.0);
    modelPosition.y += 1.0;
    // ...
  }
```

<img src="https://threejs-journey.xyz/assets/lessons/24/step-04.png" width=500>

결과물은 전체 plane 이 더 높이 떠있게 됩니다.

또는, 이렇게 plane 에게 웨이브를 줄 수도 있습니다.

``` c
  void main()
  {
    vec4 modelPosition = modelMatrix * vec4(position, 1.0);
    modelPosition.z += sin(modelPosition.x * 10.0) * 0.1;

    // ...
  }
```

<img src="https://threejs-journey.xyz/assets/lessons/24/step-05.png" width="500">


# Fragment Shader 이해하기

fragment shader 코드는 geometry 의 모든 보이는 파편(fragment) 에 적용되는데, 이것이 vertex shader 동작 후에 일어나는 이유입니다.

vertex shader 보다 다루기 쉽습니다.

